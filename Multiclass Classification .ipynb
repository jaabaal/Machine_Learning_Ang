{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Vs-All Approach or Multiclass Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 89.84 %\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from numpy import *\n",
    "\n",
    "# Load the modified mnist dataset of 20px x 20px \n",
    "dataset = loadmat('/Users/admin/Desktop/machine-learning-ex/ex3/ex3data1.mat')\n",
    "\n",
    "# Features\n",
    "X = dataset['X']\n",
    "\n",
    "# Labels\n",
    "y = dataset['y']\n",
    "\n",
    "# Merge the dataset to shuffle\n",
    "Z = np.hstack((X, y))\n",
    "\n",
    "# Shuffle the dataset to randomize the data\n",
    "np.random.shuffle(Z)\n",
    "\n",
    "# Split into training and testing set\n",
    "train_x = Z[:3750,:400] \n",
    "\n",
    "train_y = Z[:3750:,400]\n",
    "train_y = train_y.reshape(train_y.shape[0],1)\n",
    "\n",
    "test_x = Z[3750:,:400]\n",
    "\n",
    "test_y = Z[3750:,400]\n",
    "test_y = test_y.reshape(test_y.shape[0],1)\n",
    "\n",
    "# Insert additional feature x0 of all 1's\n",
    "on_s = np.ones((train_x.shape[0],1))\n",
    "train_x = np.hstack((on_s, train_x))\n",
    "\n",
    "on_s2 = np.ones((test_x.shape[0],1))\n",
    "test_x = np.hstack((on_s2, test_x))\n",
    "\n",
    "# Parameters\n",
    "theta = np.zeros((train_x.shape[1],1))\n",
    "\n",
    "# Number of distinct labels\n",
    "num_classes = 10\n",
    "\n",
    "def sigmoid(z):\n",
    "    '''\n",
    "    Function to compute the sigmoid or logistic function\n",
    "    \n",
    "    Parameters:\n",
    "        z (ndarray): Theta(transpose) times X, where X is the array of features and theta \n",
    "        is the array of parameters to be optimized.\n",
    "        \n",
    "    Returns:\n",
    "        hypothesis (ndarray): The values of z after applying the sigmoid function.\n",
    "    '''\n",
    "    hypothesis = 1.0 / (1.0 + np.exp(np.dot(-1,z)))\n",
    "    \n",
    "    return hypothesis\n",
    "\n",
    "def computeCost(theta, X, y, lmbda):\n",
    "    '''\n",
    "    Function to compute the regularized cost function\n",
    "    \n",
    "    Parameters:\n",
    "        theta (ndarray): The array of parameters to be optimized.\n",
    "        X (ndarray): The array of features.\n",
    "        y (ndarray): The array of labels.\n",
    "        lmbda (int): The regularization parameter lambda.\n",
    "        \n",
    "    Returns:\n",
    "        J (ndarray): The computed regularized cost.\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    \n",
    "    hypothesis = sigmoid(np.dot(X,theta)).reshape(y.shape[0],1)\n",
    "    \n",
    "    J = (-1/m * (np.dot(y.T, ma.log(hypothesis)) + np.dot((1 - y.T),ma.log(1 - hypothesis))))\n",
    "    + (lmbda/(2*m) * np.sum((theta[1:] ** 2),axis = 0))\n",
    "         \n",
    "    return J.reshape(1,1)\n",
    "\n",
    "def computeGradients(theta, X, y, lmbda):\n",
    "    '''\n",
    "    Function to compute the regularized gradients\n",
    "    \n",
    "    Parameters:\n",
    "        theta (ndarray): The array of parameters to be optimized.\n",
    "        X (ndarray): The array of features.\n",
    "        y (ndarray): The array of labels.\n",
    "        lmbda (int): The regularization parameter lambda.\n",
    "        \n",
    "    Returns:\n",
    "        grad (ndarray): The computed regularized gradients.\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    \n",
    "    hypothesis = sigmoid(np.dot(X,theta)).reshape(y.shape[0],1)\n",
    "    \n",
    "    theta[0] = 0\n",
    "    \n",
    "    grad = (1/m * np.dot(X.T,(hypothesis - y))).reshape(theta.shape[0],1) \n",
    "    + np.dot(lmbda/m,theta).reshape(theta.shape[0],1) \n",
    "    \n",
    "    return grad.reshape(theta.shape[0],1)\n",
    "\n",
    "def oneVsAll(X, y, num_classes, lmbda=0.1):\n",
    "    '''\n",
    "    Function to compute the optimal parameters for each label/class\n",
    "    \n",
    "    Parameters:\n",
    "        X (ndarray): The array of features.\n",
    "        y (ndarray): The array of labels.\n",
    "        num_classes (int): The total number of distinct labels.\n",
    "        lmbda (int): The regularization parameter lambda.\n",
    "        \n",
    "    Returns:\n",
    "        all_theta (ndarray): The computed optimal parameters for each label.\n",
    "    '''\n",
    "\n",
    "    all_theta = np.zeros((num_classes, X.shape[1]))\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        \n",
    "        initial_theta = np.zeros((X.shape[1],1))\n",
    "        result = opt.fmin_tnc(func=computeCost, x0=initial_theta, fprime=computeGradients, \n",
    "                              args=(X, (y == i + 1), lmbda),maxfun=50)\n",
    "        all_theta[i,:] = result[0]\n",
    "    \n",
    "    return all_theta\n",
    "        \n",
    "def predict(all_theta, X):\n",
    "    '''\n",
    "    Function to predict the labels of unseen data\n",
    "    \n",
    "    Parameters:\n",
    "        all_theta (ndarray): The computed optimal parameters for each label.\n",
    "        X (ndarray): The array of features.\n",
    "    \n",
    "    Returns:\n",
    "        prediction (ndarray): The array of predicted labels. \n",
    "    '''\n",
    "    \n",
    "    prediction = (np.argmax(np.dot(X, all_theta.T), axis=1) + 1).reshape(X.shape[0],1)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "all_theta = oneVsAll(train_x, train_y, num_classes, 0.1)\n",
    "p = predict(all_theta, test_x)\n",
    "\n",
    "correct = float(np.sum(p == test_y).ravel())\n",
    "\n",
    "# Total number of observations\n",
    "n = test_y.shape[0]\n",
    "\n",
    "# The accuracy of the model\n",
    "acc = correct/n * 100\n",
    "    \n",
    "print(f\"The accuracy is {str(round(acc,2))} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 97.52 %\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the modified mnist dataset of 20px x 20px \n",
    "dataset = loadmat('/Users/admin/Desktop/machine-learning-ex/ex3/ex3data1.mat')\n",
    "\n",
    "# Features\n",
    "X = dataset['X']\n",
    "\n",
    "# Labels\n",
    "y = dataset['y']\n",
    "\n",
    "# Insert additional feature x0 of all 1's\n",
    "on_s = np.ones((X.shape[0],1))\n",
    "X = np.hstack((on_s,X))\n",
    "\n",
    "# Load the optimized parameters for the modified mnist dataset of 20px x 20px \n",
    "dataset2 = loadmat('/Users/admin/Desktop/machine-learning-ex/ex3/ex3weights.mat')\n",
    "\n",
    "theta1 = dataset2['Theta1']\n",
    "\n",
    "theta2 = dataset2['Theta2']\n",
    "\n",
    "\n",
    "def neural_network(theta1, theta2, X):\n",
    "    \n",
    "    '''\n",
    "    Function that defines the architecture of the neural network with 400 nodes in the input layer, \n",
    "    25 nodes in the hidden layer and 10 nodes in the output layer\n",
    "    \n",
    "    Parameters:\n",
    "        theta1 (ndarray): The array of optimized weights to compute the first hidden layer.\n",
    "        theta2 (ndarray): The array of optimized weights to compute the output.\n",
    "        X (ndarray): The array of features.\n",
    "\n",
    "    Returns:\n",
    "        prediction (ndarray): The array of predicted labels. \n",
    "    '''\n",
    "    \n",
    "    hidden_layer = sigmoid(np.dot(X, theta1.T))\n",
    "    \n",
    "    hidden_layer = np.hstack((on_s, hidden_layer))\n",
    "    \n",
    "    output_layer = sigmoid(np.dot(hidden_layer, theta2.T))\n",
    "    \n",
    "    prediction = (np.argmax(output_layer,axis = 1) + 1).reshape(X.shape[0],1)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "    \n",
    "p = neural_network(theta1, theta2, X)\n",
    "\n",
    "correct = float(np.sum(p == y).ravel())\n",
    "\n",
    "# Total number of observations\n",
    "n = y.shape[0]\n",
    "\n",
    "# The accuracy of the model\n",
    "acc = correct/n * 100\n",
    "    \n",
    "print(f\"The accuracy is {str(round(acc,2))} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
